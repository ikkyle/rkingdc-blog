{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Notes:\n",
    "Need to do the whole shebang with all the images\n",
    "use color and resize with the ImageDataGenerator from keras on the fly\n",
    "Will give us that extra dimension we need. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Our last classsifier was very poor--it operated at chance--a coin flip would have had the same predictive power. A few things may have been going on that casued us to find no signal. I could be we down sampled our images too much and lost useful information, it could be that our model was poorly configured (it was), it could be we were using thr wrong model (we were), or it could be all of these. My gut (and eyes) say there is still plenty of information in our down sampled images, so we're going to try a more approproate model before we go back and try with larger images. \n",
    "\n",
    "We're going to build a convolutional neural network using keras (with Tensorflow as the backend). For starters, convolutional neural networks are much better at image classification than the mutli-layer perceptron used in the last post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeps warnings from printing for nicer blog output\n",
    "import warnings \n",
    "#warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "\n",
    "import pickle # for loading our extracted features\n",
    "import pandas as pd # for DataFame class our features are loaded into to\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for processing images\n",
    "from skimage.transform import rescale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>n</th>\n",
       "      <th>n_predictors</th>\n",
       "      <th>n_controls</th>\n",
       "      <th>filename</th>\n",
       "      <th>d_biased</th>\n",
       "      <th>d_ceiling</th>\n",
       "      <th>d_none</th>\n",
       "      <th>d_outlier</th>\n",
       "      <th>img_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>5426</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data/png/none_0000001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[57686, 61485, 61486, 61486, 61486, 61486, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>data/png/none_0000002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[57686, 61485, 61486, 61486, 61486, 61486, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>7519</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>data/png/none_0000003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[57686, 61485, 61486, 61486, 61486, 61486, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>3831</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>data/png/none_0000004.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[57686, 61485, 61486, 61486, 61486, 61486, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>6888</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>data/png/none_0000005.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[57686, 61485, 61486, 61486, 61486, 61486, 61...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  id     n  n_predictors  n_controls                   filename  \\\n",
       "0  none   1  5426             3           2  data/png/none_0000001.png   \n",
       "1  none   2   588             3           4  data/png/none_0000002.png   \n",
       "2  none   3  7519             4           3  data/png/none_0000003.png   \n",
       "3  none   4  3831             4           3  data/png/none_0000004.png   \n",
       "4  none   5  6888             4           3  data/png/none_0000005.png   \n",
       "\n",
       "   d_biased  d_ceiling  d_none  d_outlier  \\\n",
       "0         0          0       1          0   \n",
       "1         0          0       1          0   \n",
       "2         0          0       1          0   \n",
       "3         0          0       1          0   \n",
       "4         0          0       1          0   \n",
       "\n",
       "                                          img_series  \n",
       "0  [[57686, 61485, 61486, 61486, 61486, 61486, 61...  \n",
       "1  [[57686, 61485, 61486, 61486, 61486, 61486, 61...  \n",
       "2  [[57686, 61485, 61486, 61486, 61486, 61486, 61...  \n",
       "3  [[57686, 61485, 61486, 61486, 61486, 61486, 61...  \n",
       "4  [[57686, 61485, 61486, 61486, 61486, 61486, 61...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.expanduser('~/share/rkingdc-blog/regplot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this is the same file we saw in the previous post, but with the image data as an added column. Each cell in that `img_series` column is a numpy ndarray of shape `(168,168)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We'll start by building our classifier. Code will be explained inline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mod = Sequential()\n",
    "\n",
    "# create our first layer with some sensible defaults. \n",
    "# we can tweak these later if needed\n",
    "mod.add(Conv2D(filters=64, \n",
    "               kernel_size=(2,2), \n",
    "               input_shape=(126,126,3), # we've got 168x168 px photos in color\n",
    "               activation='relu'))\n",
    "\n",
    "# pooling layer reduces model complexity--good to run before flattening \n",
    "mod.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "mod.add(Flatten())\n",
    "\n",
    "# our hidden layer\n",
    "mod.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# our output layer\n",
    "# binary classification (for now) so we just need one layer \n",
    "# sigmoid forces 0,1 output\n",
    "mod.add(Dense(units=1, activation='sigmoid'))\n",
    "mod.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesing Data\n",
    "\n",
    "In image processing we'll want to pre-proccess our images before we train a model on them, by adding some random stretching, blurring, rotating, etc. Keras has utilities included to make this easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(img):\n",
    "    return rescale(img, .35, anti_aliasing=True)\n",
    "\n",
    "train_gen = ImageDataGenerator(zoom_range=.2,\n",
    "                              horizontal_flip=True,\n",
    "                              width_shift_range=.2,\n",
    "                              height_shift_range=.2,\n",
    "                           #   preprocessing_function=preproc,\n",
    "                              rescale=1/255)\n",
    "test_gen = ImageDataGenerator(rescale=1/255,\n",
    "                           #   preprocessing_function=preproc\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.flow_from_directory('data/imgs',\n",
    "                             target_size=(126,126))\n",
    "test_gen.flow_from_directory('data/imgs',\n",
    "                             target_size=(126,126))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_14_input to have 4 dimensions, but got array with shape (45000, 168, 168)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-ffd001bf4d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/regplot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/regplot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/regplot/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_14_input to have 4 dimensions, but got array with shape (45000, 168, 168)"
     ]
    }
   ],
   "source": [
    "mod.fit(x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv1D at 0x7f79c40f78d0>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x7f79c40f7860>,\n",
       " <keras.layers.core.Dense at 0x7f79c54bbc50>,\n",
       " <keras.layers.core.Dense at 0x7f79c5436438>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regplot",
   "language": "python",
   "name": "regplot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
