{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Notes:\n",
    "Need to do the whole shebang with all the images\n",
    "use color and resize with the ImageDataGenerator from keras on the fly\n",
    "Will give us that extra dimension we need. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Our last classsifier was very poor--it operated at chance--a coin flip would have had the same predictive power. A few things may have been going on that casued us to find no signal. I could be we down sampled our images too much and lost useful information, it could be that our model was poorly configured (it was), it could be we were using thr wrong model (we were), or it could be all of these. My gut (and eyes) say there is still plenty of information in our down sampled images, so we're going to try a more approproate model before we go back and try with larger images. \n",
    "\n",
    "We're going to build a convolutional neural network using keras (with Tensorflow as the backend). For starters, convolutional neural networks are much better at image classification than the mutli-layer perceptron used in the last post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keeps warnings from printing for nicer blog output\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "\n",
    "import pickle # for loading our extracted features\n",
    "import pandas as pd # for DataFame class our features are loaded into to\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "\n",
    "# for processing images\n",
    "from skimage.transform import rescale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/share/rkingdc-blog/regplot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this is the same file we saw in the previous post, but with the image data as an added column. Each cell in that `img_series` column is a numpy ndarray of shape `(168,168)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We'll start by building our classifier. Code will be explained inline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 78, 78, 36)        6948      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 39, 39, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 99,253\n",
      "Trainable params: 99,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = Sequential()\n",
    "\n",
    "mod.add(Conv2D(filters=36, \n",
    "               kernel_size=(2,2), \n",
    "               strides=(1,1), \n",
    "               input_shape=(240,240,3), # we've got 240x240 px photos in color\n",
    "               activation='relu'))\n",
    "\n",
    "# pooling layer reduces model complexity--good to run before flattening \n",
    "mod.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "mod.add(Conv2D(filters=16, \n",
    "               kernel_size=(4,4), \n",
    "               strides=(2,2), \n",
    "               input_shape=(120,120,3), # we've got 240x240 px photos in color\n",
    "               activation='relu'))\n",
    "\n",
    "mod.add(AveragePooling2D(pool_size = (2,2)))\n",
    "\n",
    "mod.add(Flatten())\n",
    "\n",
    "# our hidden layer\n",
    "mod.add(Dense(units=60, activation='relu'))\n",
    "\n",
    "# our output layer\n",
    "# binary classification (for now) so we just need one layer \n",
    "# sigmoid forces 0,1 output\n",
    "mod.add(Dense(units=1, activation='sigmoid'))\n",
    "mod.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesing Data\n",
    "\n",
    "In image processing we'll want to pre-proccess our images before we train a model on them, by adding some random stretching, blurring, rotating, etc. Keras has utilities included to make this easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator()\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory('data/imgs/train',\n",
    "                             target_size=(240,240),\n",
    "                             class_mode='binary')\n",
    "test = test_gen.flow_from_directory('data/imgs/test',\n",
    "                             target_size=(240,240),\n",
    "                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5c776cb00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit_generator(train,\n",
    "       epochs=30,\n",
    "       verbose=0,\n",
    "       validation_data=test,\n",
    "       callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "mod.save(f'trained_model_1_{str(date.today())}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = mod.evaluate_generator(test, use_multiprocessing=True, workers=2)\n",
    "print(mod.metrics_names)\n",
    "print(model_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regplot",
   "language": "python",
   "name": "regplot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
