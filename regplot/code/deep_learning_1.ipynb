{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Our last classsifier was very poor--it operated at chance--a coin flip would have had the same predictive power. A few things may have been going on that casued us to find no signal. I could be we down sampled our images too much and lost useful information, it could be that our model was poorly configured (it was), it could be we were using the wrong model (we were), or it could be all of these. To address all of these issues, we'll spend a little more time constructing model this time--examining the underlying construct of the dara itself, what we really want to learn from it, and how best to model that.  \n",
    "\n",
    "Convolutional neural networks are commonly used in image classification, but in this particular case, the strength of CNNs is something we want to avoid--namely, that the feature location within the actual image is irrelevant. In our case, where a specific feature shows up in our plot images is very important in classifying if it came from good or bad underlying data. For this reason, we'll go with a different type of neural network, a type of recurrent neural network (RNN) called a \"Long short-term memory\" neural network (LSTM). This network structure allows for a time dimension, and remembers that dimension over the course of training. Although our data don't have a time dimension, we can pretend that one dimention of our image, in this case the one that is representing by the X axis of the plot, is \"time\", and pass the dimension representing Y and red/blue/green intensity as out other dimension. This will allow our neural network to take into account how various features (say, a cluster of outlying points) relates to the rest of the image. \n",
    "\n",
    "We'll use keras for training this model, since we need more fine-tuned control over our model creation. This has TensorFlow as a backend, and allows us to run these computations on a GPU, which vastly resuces training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "We start by importing a few python modules we'll need. `warnings` and `os` for logistics, and the `keras` modules for building the model, loading and processing data, and logging results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keeps warnings from printing for nicer blog output\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Permute, Reshape, LSTM, Dropout, TimeDistributed, Dense, Activation, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These \"callbacks\" will be used during training to tell keras to write statistics about training progress to a disk and to halt training if our validation loss starts to decrease (a sign we've had enough training and we're starting to overfit our model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras callbacks\n",
    "csv_logger = CSVLogger('tf-log/epoch-log.csv', append=True, separator=';')\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/share/rkingdc-blog/regplot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We start by designing our model. The `input_dim1` is the dimension of our images--256 pixels. Since one axis will be our tiume axis, we need to know this value to make sure out model knows that we have 256 time steps for each of the 256\\*3 pixel values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256, 150)          551400    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256, 150)          180600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 150)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 100)          15100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 25601     \n",
      "=================================================================\n",
      "Total params: 772,701\n",
      "Trainable params: 772,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim1 = 256\n",
    "lstm_size = 150\n",
    "hidden_layer_size = 100\n",
    "adam_parms = {'lr': 1e-4, 'beta_1': 0.9, 'beta_2': 0.999}\n",
    "\n",
    "mod = Sequential()\n",
    "\n",
    "mod.add(Permute((2,1,3), input_shape=(input_dim1,input_dim1,3)))\n",
    "mod.add(Reshape(target_shape = (input_dim1,input_dim1*3)))\n",
    "\n",
    "# our hidden layers\n",
    "mod.add(LSTM(lstm_size, return_sequences=True))\n",
    "mod.add(LSTM(lstm_size, return_sequences=True))\n",
    "\n",
    "# dropout \n",
    "mod.add(Dropout(0.5))\n",
    "\n",
    "mod.add(TimeDistributed(Dense(hidden_layer_size), input_shape=(input_dim1, lstm_size) ))\n",
    "\n",
    "mod.add(Flatten())\n",
    "\n",
    "mod.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mod.compile(optimizer=optimizers.Adam(**adam_parms), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesing Data\n",
    "\n",
    "In image processing we'll want to pre-proccess our images before we train a model on them, by adding some random stretching, blurring, rotating, etc. Keras has utilities included to make this easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = 1/255)\n",
    "test_gen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory('data/imgs/train',\n",
    "                                      shuffle=True,\n",
    "                                      batch_size=36,\n",
    "                                      class_mode='binary')\n",
    "test = test_gen.flow_from_directory('data/imgs/test',\n",
    "                                    shuffle=True,\n",
    "                                    batch_size=36,\n",
    "                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f031ccea9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit_generator(train,\n",
    "       epochs=15,\n",
    "       verbose=0,\n",
    "       validation_data=test,\n",
    "       callbacks=[csv_logger, early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "mod.save(f'trained_model_1_{str(date.today())}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.02431063937046565, 0.9917499966025353]\n"
     ]
    }
   ],
   "source": [
    "model_eval = mod.evaluate_generator(test, use_multiprocessing=True, workers=2)\n",
    "print(mod.metrics_names)\n",
    "print(model_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
