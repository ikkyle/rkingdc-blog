{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning On a 'Real' Problem\n",
    "\n",
    "In programming, we come across problems that are often referred to as \"embarrassingly parallel\"--meaning a large number of independent operations are run sequentiually, utilizing only one of a modern machine's many processors. And every once in a while we come across problems that are also embarrassing, but more so in the light of \"a computer should be doing this\". \n",
    "\n",
    "I was pulled into a research organization a while ago that had a process where they would runupwards of 1500 models, spit out a handful of statistics and plots, and have volunteers comb through PDF reports showing figure after figure, looking for telltale signs of non-normallly distributed error in the model, outliers, and ceiling effects. If the volunteers saw anyhting, they'd notate which plot showed the issue and what the issue was, so that a research could review that model later. This struck me as a task that could be turned into a model and accomplished in minues, not days. \n",
    "\n",
    "Since this process had been happening for years, they had tens of thousands of plots and data on which ones should be flagged. The hard work on clasifying the training data had already been done, the easy part is the automation. I never had the chance to build that model--I was contracted for other work, but I always wondered how that classifier would fair. And I've decided to simulate some data to find out. \n",
    "\n",
    "In this post I'll just go through the process to turing a bunch of .png files into a training set and training a simple neural network. Future posts will dive into improving the model, using more advanced neural networks (convolutional NN vs. the multi-layer perceptron used here).\n",
    "\n",
    "## Processing Data \n",
    "\n",
    "I stuck with models that are fairly similar to what that organization produced and will only be looking at one type of plot residuals vs. fitted values, since all three of the issues will be visible in that type of plot. Below are example plots for no issues, non-normal residuals, outliers, and ceiling effect. Notice that this particular \"no issues\" plot has some points that could possibly be considered outliers, so it will be interesting to see if the model can learn to discriminate. \n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img width=\"240\" height=\"200\" alt=\"No issues\" \n",
    "         src=\"../data/png/none_0000001.png\"\n",
    "         title=\"Normal Data\">\n",
    "    <img width=\"240\" height=\"200\" alt=\"Outliers\" \n",
    "         src=\"../data/png/outlier_0000001.png\"\n",
    "         title=\"Outliers\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img width=\"240\" height=\"200\" alt=\"Non-normal\" \n",
    "         src=\"../data/png/biased_0000001.png\"\n",
    "         title=\"Non-normal Error\">\n",
    "    <img width=\"240\" height=\"200\" alt=\"Ceiling\" \n",
    "         src=\"../data/png/ceiling_0000001.png\"\n",
    "         title=\"Ceiling Effect\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### Downsampling Images\n",
    "\n",
    "You'll notice our images have a single red line in them. Color pictures are larger, and thus add to processing time, but  we don't lose information by making that line gray, so we'll want to convert all our images to grayscale. All these plots are also 480x400 pixels. We can likely make these smaller without losing the data we need to correctly clasify them. We'll do this with the `scikit-image` python package. \n",
    "\n",
    "We'll also rescale our image, making it physically smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from skimage import color\n",
    "from skimage.transform import rescale\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(\"data/png/none_0000001.png\")\n",
    "\n",
    "img_gray = color.rgb2gray(img)\n",
    "img_scale = rescale(img_gray, .35, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img_gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaled Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img_scale);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see our image has lost a fair amount of quality, but still contains all the same important information as the original and has been reduced in size by over 95%. This will be important, sd we have 40k images to train this model on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original has {n} voxels {d}\".format(n=functools.reduce(lambda a,b : a*b, img.shape), d=repr(img.shape)))\n",
    "print(\"Reduced has {n} voxels {d}\".format(n=functools.reduce(lambda a,b : a*b, img_scale.shape), d=repr(img_scale.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Training Set\n",
    "\n",
    "We've got a lot of data to process, so we'll need to write a function to convert all those images to individual numpy arrays, and also get an array that contains our response classification. Since I wrote procces to simulate all this data to output a csv with file paths and classifications, this part is pretty easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = imread(path)\n",
    "    img_gray = color.rgb2gray(img)\n",
    "    img_scale = rescale(img_gray, .35, anti_aliasing=True)\n",
    "    return img_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('data/control_file.csv')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need dummy encoded variables for the \"type\" class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(meta_data['type'], prefix='d')\n",
    "meta_data = pd.concat([meta_data, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing all files\n",
    "\n",
    "Since processing all 60k files will take a while, We'll want to do it once and save the data so I can use it later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def process_save_image(file):\n",
    "    path, name = os.path.split(file)\n",
    "    img = process_image(path)\n",
    "    imsave(os.path.join(path, '../png_redux', name), img)\n",
    "\n",
    "p = Pool(3)\n",
    "p.map(process_save_image, meta_data['filename'].tolist())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Numpy array\n",
    "\n",
    "We now have out smaller images, but we need those to be numpy arrays and we want that data linked up to our meta data. Scikit image and pandas make that easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_reader(file):\n",
    "    path, name = os.path.split(file)\n",
    "    newpath = os.path.join(path, '../png_redux', name)\n",
    "    img = imread(newpath)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this reads all images into numpy arrays in the column img_array\n",
    "meta_data['img_array'] = meta_data['filename'].apply(img_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "We'll just train a simple model here and not dive into evaluating how well it performed too much. Future posts will cover that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(meta_data, shuffle=True, test_size=0.2)\n",
    "del meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.stack(test['img_array'].tolist())\n",
    "\n",
    "train_y = train['d_none'].values\n",
    "test_y = test['d_none'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.stack(train['img_array'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MLPClassifier()\n",
    "mod.fit(train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regplot]",
   "language": "python",
   "name": "conda-env-regplot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
