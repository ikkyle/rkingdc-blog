{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "In our last post we did a total overhaul of our model, using a more appropriate neural network  type and a more powerful framework. We simplified the problem but only doing a binary classification and only using two classes: our normal and our ceiling effects plots. We were able to get fantastic validation accuracy, but never checked accuracy on a test set, and never considered alternate metrics of evaluating model performance (\"accuracy\" is not always the most informative metric). \n",
    "\n",
    "In this post, well create our final model that predicts all four classes, we'll evaluate its accuracy on a set of data held out from any training or validation, and look at a metric other than accuracy to give us more information about our model performance. \n",
    "\n",
    "We start by loading mostly the same modules we did in the last post. We add `sklearn.metrics`, for calculating Receiver Operating Characteristics (ROC) and Area Under the Curve (AUC), plus some helpful utilities from `itertools` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Permute, Reshape, LSTM, Dropout, TimeDistributed, Dense, Activation, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\n",
    "\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we define the same callbacks from the previous post, with the addition of `TensorBoard`, which allows us to interactively explore many aspects of our model, if desired.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras callbacks\n",
    "csv_logger = CSVLogger('epoch-log2.csv', append=True, separator=';')\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              verbose=0, mode='auto')\n",
    "tensor_board = TensorBoard(log_dir='./tf-log', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/share/rkingdc-blog/regplot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We need to update our model to allow for the prediction of multiple classes, rather than a simple binary classification. This requires only a few changes: output nodes to 4 instead of 1, the activation of the output node to 'softmax', and changing our loss function to \"categorical crossentropy\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256, 150)          551400    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256, 150)          180600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 150)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 100)          15100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 102404    \n",
      "=================================================================\n",
      "Total params: 849,504\n",
      "Trainable params: 849,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim1 = 256\n",
    "lstm_size = 150\n",
    "hidden_layer_size = 100\n",
    "adam_parms = {'lr': 1e-4, 'beta_1': 0.9, 'beta_2': 0.999}\n",
    "\n",
    "mod = Sequential()\n",
    "\n",
    "mod.add(Permute((2,1,3), input_shape=(input_dim1,input_dim1,3)))\n",
    "mod.add(Reshape(target_shape = (input_dim1,input_dim1*3)))\n",
    "\n",
    "# our hidden layers\n",
    "mod.add(LSTM(lstm_size, return_sequences=True))\n",
    "mod.add(LSTM(lstm_size, return_sequences=True))\n",
    "\n",
    "# dropout \n",
    "mod.add(Dropout(0.5))\n",
    "\n",
    "mod.add(TimeDistributed(Dense(hidden_layer_size), input_shape=(input_dim1, lstm_size) ))\n",
    "\n",
    "mod.add(Flatten())\n",
    "\n",
    "mod.add(Dense(4, activation='softmax'))\n",
    "\n",
    "mod.compile(optimizer=optimizers.Adam(**adam_parms), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "All this is very similar as last time--we specify the `class_mode` of the data generator to be \"categorical\" so that the vector of responses is correctly constructed, and I make the batch size a little larger, since we now have 4 classes in the data and I want to reduce the likelihood that a given batch won't be missing a class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = 1/255)\n",
    "test_gen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_gen.flow_from_directory('data/imgs/train2',\n",
    "                                      shuffle=True,\n",
    "                                      batch_size=50,\n",
    "                                      class_mode='categorical')\n",
    "val = test_gen.flow_from_directory('data/imgs/test2',\n",
    "                                    shuffle=True,\n",
    "                                    batch_size=50,\n",
    "                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit_generator(train,\n",
    "       epochs=15,\n",
    "       verbose=0,\n",
    "       validation_data=val,\n",
    "       callbacks=[csv_logger, early_stopper, tensor_board])\n",
    "mod.save(f'trained_model_2_{str(date.today())}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "With our model trained, we can now use a set of images that were excluded from the training and validation stages to see how this model can perform at classifying data it has never seen before. We know from our high validation accuracy (>99%) that we are definitely able to classify the images in the validation set well, but we need to be sure we haven't overfit our model. To do this, we create another data generator and pass that to the predict method in that model to get an array of class predictions for each image in that set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_gen = ImageDataGenerator(rescale = 1/255)\n",
    "holdout = holdout_gen.flow_from_directory('data/holdout_pngs',\n",
    "                                    shuffle=False,\n",
    "                                    batch_size=50,\n",
    "                                    class_mode='categorical')\n",
    "\n",
    "model_eval = mod.predict_generator(holdout, \n",
    "                                    use_multiprocessing=True, \n",
    "                                    workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to put the data into a pandas DataFrame to make them a little easier to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biased</th>\n",
       "      <th>ceiling</th>\n",
       "      <th>none</th>\n",
       "      <th>outlier</th>\n",
       "      <th>filename</th>\n",
       "      <th>truth</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.481814e-10</td>\n",
       "      <td>8.684403e-13</td>\n",
       "      <td>6.872439e-11</td>\n",
       "      <td>biased/biased_0000001.png</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.160816e-10</td>\n",
       "      <td>4.601760e-13</td>\n",
       "      <td>2.775461e-11</td>\n",
       "      <td>biased/biased_0000002.png</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.122757e-10</td>\n",
       "      <td>5.066882e-13</td>\n",
       "      <td>5.715443e-11</td>\n",
       "      <td>biased/biased_0000003.png</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.847489e-10</td>\n",
       "      <td>1.812751e-13</td>\n",
       "      <td>6.597836e-11</td>\n",
       "      <td>biased/biased_0000004.png</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.912477e-10</td>\n",
       "      <td>1.104792e-12</td>\n",
       "      <td>1.224962e-10</td>\n",
       "      <td>biased/biased_0000005.png</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   biased       ceiling          none       outlier  \\\n",
       "0     1.0  2.481814e-10  8.684403e-13  6.872439e-11   \n",
       "1     1.0  4.160816e-10  4.601760e-13  2.775461e-11   \n",
       "2     1.0  3.122757e-10  5.066882e-13  5.715443e-11   \n",
       "3     1.0  1.847489e-10  1.812751e-13  6.597836e-11   \n",
       "4     1.0  3.912477e-10  1.104792e-12  1.224962e-10   \n",
       "\n",
       "                    filename   truth predicted_class  \n",
       "0  biased/biased_0000001.png  biased          biased  \n",
       "1  biased/biased_0000002.png  biased          biased  \n",
       "2  biased/biased_0000003.png  biased          biased  \n",
       "3  biased/biased_0000004.png  biased          biased  \n",
       "4  biased/biased_0000005.png  biased          biased  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame(model_eval, columns = holdout.class_indices.keys())\n",
    "preds['filename'] = holdout.filenames\n",
    "preds['truth'] = preds['filename'].apply(os.path.dirname)\n",
    "preds['predicted_class'] = preds[list(holdout.class_indices.keys())].idxmax(1)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is quite high with this model on the training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.5% Accuracy\n"
     ]
    }
   ],
   "source": [
    "print(str(np.mean(preds['predicted_class'] == preds['truth']) * 100) + \"% Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful metric in classification is the Area Under the Curve (AUC), which takes into account measures of sensitivity and specificity in the model, looking at the predicted probabilities rather than the final classes. The keras model assigns a classification based on the maximal probability, but if we want to reduce type II error, we might want to set our own thresholds rather than use keras's. AUC ranges from 0-1, with 0.5 representing a model that performs completely at chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truths(df, class_label):\n",
    "    y_truth = df['truth'] == class_label\n",
    "    return y_truth.astype(int).values, df[class_label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = len(holdout.class_indices)\n",
    "classes = holdout.class_indices.keys()\n",
    "lw=2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for k,i in holdout.class_indices.items():\n",
    "    t, p = get_truths(preds, k)\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(t, p)\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"overall\"] = all_fpr\n",
    "tpr[\"overall\"] = mean_tpr\n",
    "roc_auc[\"overall\"] = metrics.auc(fpr[\"overall\"], tpr[\"overall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biased AUC: 1.000000\n",
      "ceiling AUC: 0.999891\n",
      "none AUC: 0.999808\n",
      "outlier AUC: 0.999961\n",
      "Overall AUC: 0.999931\n"
     ]
    }
   ],
   "source": [
    "print_auc = (lambda x,v: print('{v} AUC: {x:.6f}'.format(v=v, x=x)))\n",
    "for k,v in holdout.class_indices.items():\n",
    "    print_auc(roc_auc[v], k)\n",
    "print_auc(roc_auc['overall'], \"Overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our AUC to be as close to 1 as possible, so that we are getting values of .999 (at minimum) is very promising. With a few adjustments to cutoff thresholds, we may be able to get a classifier with almost zero risk of letting erroneous plots slip through the cracks. \n",
    "\n",
    "In the next post, we'll go through how to set those thresholds to reduce type II error, and future posts will transform this model into a useful tool, by making it available as a HTTP request endpoint. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regplot]",
   "language": "python",
   "name": "conda-env-regplot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
